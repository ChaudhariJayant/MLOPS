{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6dc929d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8a2bc828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\Projects\\\\Machine Learning\\\\MLOPS'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# os.chdir(\"../\")\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9883ad0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install dagshub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "89eeb1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dagshub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c0ddb274",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"MLFLOW_TRACKING_URI\"] = \"https://dagshub.com/ChaudhariJayant/MLOPS.mlflow\"\n",
    "os.environ[\"MLFLOW_TRACKING_USERNAME\"] = \"ChaudhariJayant\"\n",
    "os.environ[\"MLFLOW_TRACKING_PASSWORD\"] = \"759117ca6914d4d199daa2dbba749716a41af74d\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a028a005",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class ModelEvaluationConfig:\n",
    "    root_dir: Path\n",
    "    test_data_path:Path\n",
    "    model_path:Path\n",
    "    all_params: dict\n",
    "    metric_file_name: Path\n",
    "    target_column: str\n",
    "    mlflow_uri:str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1feb4e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.mlProject.constants import *\n",
    "from src.mlProject.utils.common import read_yaml, create_directories, save_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "27c19632",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH,\n",
    "        schema_filepath = SCHEMA_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        self.schema = read_yaml(schema_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "\n",
    "    def get_model_evaluation_config(self)-> ModelEvaluationConfig:\n",
    "        config =self.config.model_evaluation\n",
    "        params =self.params.ElasticNet\n",
    "        schema = self.schema.TARGET_COLUMN\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        model_evaluation_config = ModelEvaluationConfig(\n",
    "            root_dir = config.root_dir,\n",
    "            test_data_path = config.test_data_path,\n",
    "            model_path= config.model_path,\n",
    "            all_params=params,\n",
    "            metric_file_name= config.metric_file_name,\n",
    "            target_column=schema.name,\n",
    "            mlflow_uri= \"https://dagshub.com/ChaudhariJayant/MLOPS.mlflow\"\n",
    "        )\n",
    "        return model_evaluation_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8ed131d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from urllib.parse import urlparse\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import numpy as np\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b62fbc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from venv import logger\n",
    "\n",
    "\n",
    "class ModelEvaluation:\n",
    "    def __init__(self,config: ModelEvaluationConfig):\n",
    "        self.config = config\n",
    "    \n",
    "    def eval_metrics(self, actual, pred):\n",
    "        rsme = np.sqrt(mean_squared_error(actual, pred))\n",
    "        mae = mean_absolute_error(actual, pred)\n",
    "        r2 = r2_score(actual, pred)\n",
    "\n",
    "        return rsme, mae, r2\n",
    "    \n",
    "    def log_into_mlflow(self):\n",
    "        test_data = pd.read_csv(self.config.test_data_path)\n",
    "        model = joblib.load(self.config.model_path)\n",
    "\n",
    "        test_x = test_data.drop(self.config.target_column, axis=1)\n",
    "        test_y = test_data[[self.config.target_column]]\n",
    "\n",
    "        mlflow.set_registry_uri(self.config.mlflow_uri)\n",
    "        tracking_url_type_store = urlparse(mlflow.get_tracking_uri()).scheme\n",
    "        # logger.info(f\"url fuck up {urlparse(mlflow.get_tracking_uri())}\")\n",
    "        \n",
    "\n",
    "        with mlflow.start_run():\n",
    "            \n",
    "            predicted_qualities = model.predict(test_x)\n",
    "            # print(predicted_qualities)\n",
    "\n",
    "            (rsme, mae, r2) = self.eval_metrics(test_y, predicted_qualities)\n",
    "\n",
    "            \n",
    "            scores = {\"rsme\":rsme, \"mae\":mae, \"r2\":r2}\n",
    "            save_json(path=Path(self.config.metric_file_name), data=scores)\n",
    "\n",
    "            \n",
    "            \n",
    "            mlflow.log_params(self.config.all_params)\n",
    "\n",
    "            mlflow.log_metric(\"rsmr\", rsme)\n",
    "            mlflow.log_metric(\"r2\", r2)\n",
    "            mlflow.log_metric(\"mae\", mae)\n",
    "            logger.info(f\"url fuck up {urlparse(mlflow.get_tracking_uri()).scheme}\")\n",
    "\n",
    "           \n",
    "\n",
    "            mlflow.sklearn.log_model(sk_model= model, name=\"ElasticnetModel\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6e57c3",
   "metadata": {},
   "source": [
    "New Class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "553fee25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-11-16 13:02:39,740: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2025-11-16 13:02:39,742: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2025-11-16 13:02:39,744: INFO: common: yaml file: schema.yaml loaded successfully]\n",
      "[2025-11-16 13:02:39,747: INFO: common: Created directory at: artifacts]\n",
      "[2025-11-16 13:02:39,748: INFO: common: Created directory at: artifacts/model_evalution]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chaud\\anaconda3\\envs\\ML_venv\\lib\\site-packages\\sklearn\\base.py:442: InconsistentVersionWarning: Trying to unpickle estimator ElasticNet from version 1.3.0 when using version 1.7.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-11-16 13:02:40,101: INFO: common: Json file saved at: artifacts\\model_evalution\\metrics.json]\n",
      "[2025-11-16 13:02:41,019: INFO: 3058600124: url fuck up https]\n",
      "üèÉ View run big-squid-56 at: https://dagshub.com/ChaudhariJayant/MLOPS.mlflow/#/experiments/0/runs/a4d591cce2e448e6938d649cb42f3a19\n",
      "üß™ View experiment at: https://dagshub.com/ChaudhariJayant/MLOPS.mlflow/#/experiments/0\n",
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\chaud\\anaconda3\\envs\\ML_venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3579, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\chaud\\AppData\\Local\\Temp\\ipykernel_25392\\3351084627.py\", line 7, in <module>\n",
      "    raise e\n",
      "  File \"C:\\Users\\chaud\\AppData\\Local\\Temp\\ipykernel_25392\\3351084627.py\", line 5, in <module>\n",
      "    model_evaluation_config.log_into_mlflow()\n",
      "  File \"C:\\Users\\chaud\\AppData\\Local\\Temp\\ipykernel_25392\\3058600124.py\", line 49, in log_into_mlflow\n",
      "    mlflow.sklearn.log_model(sk_model= model, name=\"ElasticnetModel\")\n",
      "  File \"c:\\Users\\chaud\\anaconda3\\envs\\ML_venv\\lib\\site-packages\\mlflow\\sklearn\\__init__.py\", line 426, in log_model\n",
      "    return Model.log(\n",
      "  File \"c:\\Users\\chaud\\anaconda3\\envs\\ML_venv\\lib\\site-packages\\mlflow\\models\\model.py\", line 1165, in log\n",
      "    model = _create_logged_model(\n",
      "  File \"c:\\Users\\chaud\\anaconda3\\envs\\ML_venv\\lib\\site-packages\\mlflow\\tracking\\fluent.py\", line 2330, in _create_logged_model\n",
      "    return MlflowClient()._create_logged_model(\n",
      "  File \"c:\\Users\\chaud\\anaconda3\\envs\\ML_venv\\lib\\site-packages\\mlflow\\tracking\\client.py\", line 5500, in _create_logged_model\n",
      "    return self._tracking_client.create_logged_model(\n",
      "  File \"c:\\Users\\chaud\\anaconda3\\envs\\ML_venv\\lib\\site-packages\\mlflow\\telemetry\\track.py\", line 30, in wrapper\n",
      "    result = func(*args, **kwargs)\n",
      "  File \"c:\\Users\\chaud\\anaconda3\\envs\\ML_venv\\lib\\site-packages\\mlflow\\tracking\\_tracking_service\\client.py\", line 870, in create_logged_model\n",
      "    return self.store.create_logged_model(\n",
      "  File \"c:\\Users\\chaud\\anaconda3\\envs\\ML_venv\\lib\\site-packages\\mlflow\\store\\tracking\\rest_store.py\", line 932, in create_logged_model\n",
      "    response_proto = self._call_endpoint(CreateLoggedModel, req_body)\n",
      "  File \"c:\\Users\\chaud\\anaconda3\\envs\\ML_venv\\lib\\site-packages\\mlflow\\store\\tracking\\rest_store.py\", line 203, in _call_endpoint\n",
      "    return call_endpoint(\n",
      "  File \"c:\\Users\\chaud\\anaconda3\\envs\\ML_venv\\lib\\site-packages\\mlflow\\utils\\rest_utils.py\", line 596, in call_endpoint\n",
      "    response = verify_rest_response(response, endpoint)\n",
      "  File \"c:\\Users\\chaud\\anaconda3\\envs\\ML_venv\\lib\\site-packages\\mlflow\\utils\\rest_utils.py\", line 315, in verify_rest_response\n",
      "    raise RestException(json.loads(response.text))\n",
      "mlflow.exceptions.RestException: INTERNAL_ERROR: Response: {'error': 'unsupported endpoint, please contact support@dagshub.com'}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\chaud\\anaconda3\\envs\\ML_venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2170, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"c:\\Users\\chaud\\anaconda3\\envs\\ML_venv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1457, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"c:\\Users\\chaud\\anaconda3\\envs\\ML_venv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1348, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"c:\\Users\\chaud\\anaconda3\\envs\\ML_venv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1195, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"c:\\Users\\chaud\\anaconda3\\envs\\ML_venv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1110, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "  File \"c:\\Users\\chaud\\anaconda3\\envs\\ML_venv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 992, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "  File \"c:\\Users\\chaud\\anaconda3\\envs\\ML_venv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 804, in lines\n",
      "    return self._sd.lines\n",
      "  File \"c:\\Users\\chaud\\anaconda3\\envs\\ML_venv\\lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"c:\\Users\\chaud\\anaconda3\\envs\\ML_venv\\lib\\site-packages\\stack_data\\core.py\", line 734, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"c:\\Users\\chaud\\anaconda3\\envs\\ML_venv\\lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"c:\\Users\\chaud\\anaconda3\\envs\\ML_venv\\lib\\site-packages\\stack_data\\core.py\", line 677, in included_pieces\n",
      "    scope_pieces = self.scope_pieces\n",
      "  File \"c:\\Users\\chaud\\anaconda3\\envs\\ML_venv\\lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"c:\\Users\\chaud\\anaconda3\\envs\\ML_venv\\lib\\site-packages\\stack_data\\core.py\", line 614, in scope_pieces\n",
      "    scope_start, scope_end = self.source.line_range(self.scope)\n",
      "  File \"c:\\Users\\chaud\\anaconda3\\envs\\ML_venv\\lib\\site-packages\\stack_data\\core.py\", line 178, in line_range\n",
      "    return line_range(self.asttext(), node)\n",
      "AttributeError: 'Source' object has no attribute 'asttext'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    model_evaluation_config = config.get_model_evaluation_config()\n",
    "    model_evaluation_config = ModelEvaluation(config=model_evaluation_config)\n",
    "    model_evaluation_config.log_into_mlflow()\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6979adfc",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
